{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the scores and the models I used previously\n",
    "scores = 0.7810,0.63,0.763,0.828,0.702,0.837,0.830,0.802\n",
    "models = 'k-NN','decision tree','random forest','svm linear','svm rbf','logistic','fc RNN','CNN'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>k-NN</td>\n",
       "      <td>0.781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>decision tree</td>\n",
       "      <td>0.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>random forest</td>\n",
       "      <td>0.763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>svm linear</td>\n",
       "      <td>0.828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>svm rbf</td>\n",
       "      <td>0.702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>fc RNN</td>\n",
       "      <td>0.830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.802</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Models  Scores\n",
       "0           k-NN   0.781\n",
       "1  decision tree   0.630\n",
       "2  random forest   0.763\n",
       "3     svm linear   0.828\n",
       "4        svm rbf   0.702\n",
       "5       logistic   0.837\n",
       "6         fc RNN   0.830\n",
       "7            CNN   0.802"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# putting them in a DF\n",
    "results_df = pd.DataFrame({'Models':models,'Scores':scores})\n",
    "results_df\n",
    "# Out of all the models the ones closer to the top are linear SVM, Logistic Regression and RNN\n",
    "# I choose Losgistic regression both because it has the best result and\n",
    "# because it is a simpler model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "with np.load('cifar4-train.npz', allow_pickle=False) as data:\n",
    "    cifar = dict(data.items())\n",
    "with np.load('cifar4-test.npz',allow_pickle=False) as test:\n",
    "    cifar_test = dict(test.items())\n",
    "    \n",
    "X = cifar['overfeat']\n",
    "y = cifar['labels']\n",
    "\n",
    "X_test = cifar_test['overfeat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-training the logistic regression with all the data\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import ParameterGrid, cross_validate\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "Logreg  =  SGDClassifier(\n",
    "    # Set logistic loss\n",
    "    loss='log',\n",
    "    # Set max number of iterations and stopping criteria\n",
    "    max_iter=1000, tol=1e-3, n_jobs = -1 # to use all cores\n",
    ")\n",
    "\n",
    "pca = PCA()\n",
    "\n",
    "# one grid with a PCA step where i tune the alpha and the pca\n",
    "grid =ParameterGrid({\n",
    "    'logreg__alpha':[0.00001,0.0001,0.0005,0.001],\n",
    "    'pca__n_components':np.arange(350,450,20)\n",
    "    \n",
    "})\n",
    "\n",
    "#a second grid where i only tune the alpha as I wont use pca\n",
    "grid1=ParameterGrid(\n",
    "{\n",
    "    'pca':[None],\n",
    "    'logreg__alpha':[0.00001,0.0001,0.0005,0.001],\n",
    "\n",
    "})\n",
    "\n",
    "# Making lists to append the scores\n",
    "val_scores_pca = []\n",
    "val_scores = []\n",
    "\n",
    "# The pipeline with the PCA as a step\n",
    "pipe = Pipeline([\n",
    "    ('pca',pca),\n",
    "    ('logreg',Logreg)    \n",
    "])\n",
    "\n",
    "# Doing the grid search using the PCA pipe\n",
    "\n",
    "for params_dict_pca in grid:\n",
    "    pipe.set_params(**params_dict_pca)\n",
    "    # 5-fold Cross-validation with n_jobs = -1 to use all the processors\n",
    "    cv_results = cross_validate(pipe, X, y, cv=5, n_jobs=-1,\n",
    "                                return_train_score=False)\n",
    "    # Appending the criss-validation results in the previous dict to centralize\n",
    "    params_dict_pca['mean val accuracy'] = cv_results['test_score'].mean()\n",
    "    params_dict_pca['std of val accuracy'] = cv_results['test_score'].std()\n",
    "    val_scores_pca.append(params_dict_pca)\n",
    "    \n",
    "# Doing the same for the grid without the PCA\n",
    "for params_dict in grid1:\n",
    "    pipe.set_params(**params_dict)\n",
    "    \n",
    "   \n",
    "    cv_results = cross_validate(pipe, X, y, cv=5, n_jobs=-1,\n",
    "                                return_train_score=False)\n",
    "\n",
    "    params_dict['mean val accuracy'] = cv_results['test_score'].mean()\n",
    "    params_dict['std of val accuracy'] = cv_results['test_score'].std()\n",
    "    val_scores.append(params_dict)\n",
    "    \n",
    "# A DF with the hyperparameters and the results\n",
    "scores_df = pd.DataFrame(val_scores)\n",
    "scores_df = scores_df.sort_values(by='mean val accuracy',ascending = False)\n",
    "scores_df = scores_df.reset_index(drop = True)\n",
    "\n",
    "# With the PCA\n",
    "scores_df_pca = pd.DataFrame(val_scores_pca)\n",
    "scores_df_pca = scores_df_pca.sort_values(by='mean val accuracy',ascending = False)\n",
    "scores_df_pca = scores_df_pca.reset_index(drop = True)\n",
    "\n",
    "# finding the best score from both DFs  and putting it in a dict\n",
    "if scores_df['mean val accuracy'][0] > scores_df_pca['mean val accuracy'][0]:\n",
    "    best_dict = {'pca':[None],\n",
    "                 'alpha':scores_df['logreg__alpha'][0],\n",
    "                 'accuracy':scores_df['mean val accuracy'][0],\n",
    "                 'std':scores_df['std of val accuracy'][0]\n",
    "                }\n",
    "else:\n",
    "    best_dict = {'pca':scores_df_pca['pca__n_components'][0],\n",
    "                 'alpha':scores_df_pca['logreg__alpha'][0],\n",
    "                 'accuracy':scores_df_pca['mean val accuracy'][0],\n",
    "                 'std':scores_df_pca['std of val accuracy'][0]\n",
    "                }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression - top ccuracy across folds: 0.8384 (std: 0.0094) with 390 components and alpha 0.0005\n"
     ]
    }
   ],
   "source": [
    "# fitting the best parameters\n",
    "Logreg  =  SGDClassifier(\n",
    "    # Set logistic loss\n",
    "    loss='log',\n",
    "    max_iter=1000, tol=1e-3, n_jobs = -1, alpha = best_dict['alpha']\n",
    "    \n",
    ")\n",
    "\n",
    "pca = PCA(n_components=best_dict['pca'])\n",
    "\n",
    "pipe_best = Pipeline([\n",
    "    ('pca',pca),\n",
    "    ('logreg',Logreg)    \n",
    "])\n",
    "# fitting th\n",
    "pipe_best.fit(X,y)\n",
    "\n",
    "#printing the best results\n",
    "print('Logistic Regression - top ccuracy across folds:',\n",
    "      '{:.4f} (std: {:.4f}) with {} components and alpha {}'.format(\n",
    "          best_dict['accuracy'],\n",
    "          best_dict['std'],\n",
    "          best_dict['pca'],\n",
    "          best_dict['alpha']\n",
    "          ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pipe_best.predict(X)\n",
    "\n",
    "np.save('test-predictions',arr=preds,allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Anaconda3]",
   "language": "python",
   "name": "conda-env-Anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
